{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header_cell"
   },
   "source": [
    "# üíº Employee Salary Prediction Management\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/)\n",
    "\n",
    "**Objective:** Predict whether an employee earns more than $50K per year using machine learning\n",
    "\n",
    "**Dataset:** Employee demographic and work-related features\n",
    "\n",
    "**Model:** Logistic Regression Classifier\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup_cell"
   },
   "source": [
    "## üîß Setup and Installation\n",
    "\n",
    "First, let's install and import all necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_libraries",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [],
   "source": [
    "# Install required libraries (uncomment if running in a fresh environment)\n",
    "# !pip install pandas numpy matplotlib seaborn scikit-learn\n",
    "\n",
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, ConfusionMatrixDisplay\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "data_upload_cell"
   },
   "source": [
    "## üìÅ Data Upload and Loading\n",
    "\n",
    "**Option 1:** Upload your CSV file using the file upload widget below\n",
    "\n",
    "**Option 2:** Use the sample data provided in the next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "upload_data",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    }
   },
   "outputs": [],
   "source": [
    "# For Google Colab: Upload files\n",
    "from google.colab import files\n",
    "import io\n",
    "\n",
    "print(\"üì§ Upload your employee data CSV file:\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Load the uploaded file\n",
    "filename = list(uploaded.keys())[0]\n",
    "df = pd.read_csv(io.BytesIO(uploaded[filename]))\n",
    "print(f\"‚úÖ Successfully loaded: {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sample_data_alternative"
   },
   "outputs": [],
   "source": [
    "# Alternative: Create sample data if no file uploaded\n",
    "# Uncomment and run this cell if you want to use sample data instead\n",
    "\n",
    "# sample_data = {\n",
    "#     'age': [39, 50, 38, 53, 28, 37, 49, 52, 31, 42, 30, 23, 32, 40, 34],\n",
    "#     'workclass': ['State-gov', 'Self-emp-not-inc', 'Private', 'Private', 'Private', 'Private', 'Private', 'Self-emp-not-inc', 'Private', 'Private', 'State-gov', 'Private', 'Private', 'Private', 'Private'],\n",
    "#     'fnlwgt': [77516, 83311, 215646, 234721, 338409, 284582, 160187, 209642, 45781, 159449, 141297, 122272, 205019, 121772, 245487],\n",
    "#     'education': ['Bachelors', 'Bachelors', 'HS-grad', '11th', 'Bachelors', 'Masters', '9th', 'HS-grad', 'Masters', 'Bachelors', 'Bachelors', 'Bachelors', 'Assoc-acdm', 'Bachelors', 'Masters'],\n",
    "#     'educational-num': [13, 13, 9, 7, 13, 14, 5, 9, 14, 13, 13, 13, 12, 13, 14],\n",
    "#     'marital-status': ['Never-married', 'Married-civ-spouse', 'Divorced', 'Married-civ-spouse', 'Married-civ-spouse', 'Married-civ-spouse', 'Married-spouse-absent', 'Married-civ-spouse', 'Never-married', 'Married-civ-spouse', 'Married-civ-spouse', 'Never-married', 'Married-civ-spouse', 'Married-civ-spouse', 'Never-married'],\n",
    "#     'occupation': ['Adm-clerical', 'Exec-managerial', 'Handlers-cleaners', 'Handlers-cleaners', 'Prof-specialty', 'Exec-managerial', 'Other-service', 'Exec-managerial', 'Prof-specialty', 'Exec-managerial', 'Prof-specialty', 'Adm-clerical', 'Exec-managerial', 'Prof-specialty', 'Exec-managerial'],\n",
    "#     'relationship': ['Not-in-family', 'Husband', 'Not-in-family', 'Husband', 'Wife', 'Wife', 'Not-in-family', 'Husband', 'Not-in-family', 'Husband', 'Husband', 'Own-child', 'Husband', 'Husband', 'Not-in-family'],\n",
    "#     'race': ['White', 'White', 'White', 'Black', 'Black', 'White', 'Black', 'White', 'White', 'White', 'Asian-Pac-Islander', 'Black', 'White', 'Black', 'White'],\n",
    "#     'gender': ['Male', 'Male', 'Male', 'Male', 'Female', 'Female', 'Female', 'Male', 'Female', 'Male', 'Male', 'Female', 'Male', 'Male', 'Female'],\n",
    "#     'capital-gain': [2174, 0, 0, 0, 0, 0, 0, 0, 14084, 5178, 2407, 0, 0, 0, 0],\n",
    "#     'capital-loss': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "#     'hours-per-week': [40, 13, 40, 40, 40, 40, 16, 45, 50, 40, 40, 30, 50, 40, 30],\n",
    "#     'native-country': ['United-States', 'United-States', 'United-States', 'United-States', 'Cuba', 'United-States', 'Jamaica', 'United-States', 'United-States', 'United-States', 'South', 'United-States', 'United-States', 'United-States', 'United-States'],\n",
    "#     'income': ['<=50K', '<=50K', '<=50K', '<=50K', '>50K', '>50K', '<=50K', '>50K', '>50K', '>50K', '>50K', '<=50K', '>50K', '>50K', '<=50K']\n",
    "# }\n",
    "# df = pd.DataFrame(sample_data)\n",
    "# print(\"‚úÖ Sample data created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eda_cell"
   },
   "source": [
    "## üîç Exploratory Data Analysis (EDA)\n",
    "\n",
    "Let's explore our dataset structure and understand the data better:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "data_preview",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    }
   },
   "outputs": [],
   "source": [
    "# Display basic information\n",
    "print(\"üìä Dataset Shape:\", df.shape)\n",
    "print(\"\\nüìã First 5 rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "data_info",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [],
   "source": [
    "# Dataset information\n",
    "print(\"‚ÑπÔ∏è Dataset Info:\")\n",
    "df.info()\n",
    "print(\"\\nüî¢ Statistical Summary:\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "missing_values",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"‚ùì Missing Values:\")\n",
    "missing_data = df.isnull().sum()\n",
    "if missing_data.sum() == 0:\n",
    "    print(\"‚úÖ No missing values found!\")\n",
    "else:\n",
    "    print(missing_data[missing_data > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "preprocessing_cell"
   },
   "source": [
    "## üßπ Data Preprocessing\n",
    "\n",
    "Clean the data and prepare it for machine learning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "handle_missing",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [],
   "source": [
    "# Handle missing values and ambiguous entries\n",
    "df_clean = df.copy()\n",
    "\n",
    "# Fill missing values\n",
    "for col in df_clean.columns:\n",
    "    if df_clean[col].dtype == 'object':\n",
    "        df_clean[col].fillna(df_clean[col].mode()[0], inplace=True)\n",
    "    else:\n",
    "        df_clean[col].fillna(df_clean[col].median(), inplace=True)\n",
    "\n",
    "# Replace '?' with 'Others' in common columns\n",
    "for col in ['workclass', 'occupation', 'native-country']:\n",
    "    if col in df_clean.columns:\n",
    "        df_clean[col] = df_clean[col].replace('?', 'Others')\n",
    "\n",
    "print(\"‚úÖ Data cleaning completed!\")\n",
    "print(f\"üìä Clean dataset shape: {df_clean.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "visualization_cell"
   },
   "source": [
    "## üìà Data Visualization\n",
    "\n",
    "Visualize the data to understand patterns and distributions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "target_distribution",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    }
   },
   "outputs": [],
   "source": [
    "# Target variable distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.countplot(data=df_clean, x='income', palette='Set2')\n",
    "plt.title('üí∞ Income Distribution')\n",
    "plt.xlabel('Income Category')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "income_counts = df_clean['income'].value_counts()\n",
    "plt.pie(income_counts.values, labels=income_counts.index, autopct='%1.1f%%', colors=sns.color_palette('Set2'))\n",
    "plt.title('üí∞ Income Distribution (%)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üìä Income Distribution:\")\n",
    "print(df_clean['income'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "feature_analysis",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    }
   },
   "outputs": [],
   "source": [
    "# Analyze key features\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Age distribution by income\n",
    "sns.boxplot(data=df_clean, x='income', y='age', ax=axes[0,0], palette='Set1')\n",
    "axes[0,0].set_title('üë§ Age vs Income')\n",
    "\n",
    "# Education vs Income (if education column exists)\n",
    "if 'education' in df_clean.columns:\n",
    "    education_income = pd.crosstab(df_clean['education'], df_clean['income'], normalize='index')\n",
    "    education_income.plot(kind='bar', ax=axes[0,1], color=['lightcoral', 'lightblue'])\n",
    "    axes[0,1].set_title('üéì Education vs Income')\n",
    "    axes[0,1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Gender vs Income (if gender column exists)\n",
    "if 'gender' in df_clean.columns:\n",
    "    sns.countplot(data=df_clean, x='gender', hue='income', ax=axes[1,0], palette='Set3')\n",
    "    axes[1,0].set_title('üë´ Gender vs Income')\n",
    "\n",
    "# Hours per week vs Income (if hours-per-week column exists)\n",
    "if 'hours-per-week' in df_clean.columns:\n",
    "    sns.boxplot(data=df_clean, x='income', y='hours-per-week', ax=axes[1,1], palette='Set2')\n",
    "    axes[1,1].set_title('‚è∞ Hours per Week vs Income')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "encoding_cell"
   },
   "source": [
    "## üî¢ Feature Engineering & Encoding\n",
    "\n",
    "Convert categorical variables to numerical format for machine learning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "label_encoding",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [],
   "source": [
    "# Label encoding for categorical features\n",
    "encoders = {}\n",
    "categorical_columns = df_clean.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Remove target variable from categorical columns\n",
    "if 'income' in categorical_columns:\n",
    "    categorical_columns.remove('income')\n",
    "\n",
    "print(f\"üè∑Ô∏è Encoding categorical columns: {categorical_columns}\")\n",
    "\n",
    "# Encode categorical features\n",
    "for col in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    df_clean[col] = le.fit_transform(df_clean[col])\n",
    "    encoders[col] = le\n",
    "    print(f\"   ‚úÖ {col}: {len(le.classes_)} unique values\")\n",
    "\n",
    "# Encode target variable\n",
    "target_mapping = {'<=50K': 0, '>50K': 1}\n",
    "df_clean['income'] = df_clean['income'].map(target_mapping)\n",
    "\n",
    "print(\"\\nüéØ Target variable mapping:\", target_mapping)\n",
    "print(\"‚úÖ All encoding completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "encoded_preview",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    }
   },
   "outputs": [],
   "source": [
    "# Preview encoded data\n",
    "print(\"üî¢ Encoded Dataset Preview:\")\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "modeling_cell"
   },
   "source": [
    "## ü§ñ Machine Learning Model\n",
    "\n",
    "Train and evaluate our salary prediction model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "train_test_split",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [],
   "source": [
    "# Prepare features and target\n",
    "X = df_clean.drop('income', axis=1)\n",
    "y = df_clean['income']\n",
    "\n",
    "print(f\"üìä Features shape: {X.shape}\")\n",
    "print(f\"üéØ Target shape: {y.shape}\")\n",
    "print(f\"üè∑Ô∏è Feature columns: {list(X.columns)}\")\n",
    "\n",
    "# Check class distribution\n",
    "print(f\"\\nüìà Class distribution:\")\n",
    "print(y.value_counts())\n",
    "\n",
    "# Train-test split with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÇÔ∏è Data split completed:\")\n",
    "print(f\"   üìö Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"   üß™ Test set: {X_test.shape[0]} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "model_training",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [],
   "source": [
    "# Train Logistic Regression model\n",
    "print(\"üöÄ Starting model training...\")\n",
    "\n",
    "model = LogisticRegression(max_iter=200, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"‚úÖ Model training completed!\")\n",
    "print(f\"üîß Model: {model.__class__.__name__}\")\n",
    "print(f\"üìä Features used: {len(X.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "evaluation_cell"
   },
   "source": [
    "## üìä Model Evaluation\n",
    "\n",
    "Assess the performance of our trained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "model_prediction",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_proba = model.predict_proba(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"üéØ Model Accuracy: {accuracy:.2%}\")\n",
    "\n",
    "# Detailed classification report\n",
    "print(f\"\\nüìã Detailed Classification Report:\")\n",
    "print(\"=\" * 50)\n",
    "print(classification_report(y_test, y_pred, target_names=['<=50K', '>50K']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "confusion_matrix",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    }
   },
   "outputs": [],
   "source": [
    "# Confusion Matrix Visualization\n",
    "plt.figure(figsize=(8, 6))\n",
    "ConfusionMatrixDisplay.from_estimator(\n",
    "    model, X_test, y_test, \n",
    "    display_labels=['<=50K', '>50K'], \n",
    "    cmap='Blues',\n",
    "    values_format='d'\n",
    ")\n",
    "plt.title('üéØ Confusion Matrix', fontsize=16, pad=20)\n",
    "plt.show()\n",
    "\n",
    "# Additional metrics\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"\\nüìä Additional Metrics:\")\n",
    "print(f\"   üéØ Precision: {precision:.3f}\")\n",
    "print(f\"   üîç Recall: {recall:.3f}\")\n",
    "print(f\"   ‚öñÔ∏è F1-Score: {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "prediction_cell"
   },
   "source": [
    "## üîÆ Individual Predictions\n",
    "\n",
    "Test the model with custom employee data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sample_prediction",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [],
   "source": [
    "# Example prediction for a new employee\n",
    "# Modify these values to test different scenarios\n",
    "\n",
    "print(\"üîÆ Sample Employee Prediction\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Create a sample employee (adjust values as needed)\n",
    "sample_employee = {\n",
    "    'age': 35,\n",
    "    'fnlwgt': 150000,  # Final weight (if available)\n",
    "    'educational-num': 13,  # Education number (if available)\n",
    "    'capital-gain': 0,\n",
    "    'capital-loss': 0,\n",
    "    'hours-per-week': 45\n",
    "}\n",
    "\n",
    "# Add encoded categorical features (using first available class)\n",
    "for col in categorical_columns:\n",
    "    if col in X.columns:\n",
    "        sample_employee[col] = 0  # Using first encoded value\n",
    "\n",
    "# Ensure all features are present\n",
    "sample_df = pd.DataFrame([sample_employee])\n",
    "sample_df = sample_df.reindex(columns=X.columns, fill_value=0)\n",
    "\n",
    "# Make prediction\n",
    "prediction = model.predict(sample_df)[0]\n",
    "probability = model.predict_proba(sample_df)[0]\n",
    "\n",
    "result = \"<=50K\" if prediction == 0 else \">50K\"\n",
    "confidence = probability[prediction]\n",
    "\n",
    "print(f\"üë§ Sample Employee Profile:\")\n",
    "for key, value in sample_employee.items():\n",
    "    if key in ['age', 'hours-per-week', 'capital-gain', 'capital-loss']:\n",
    "        print(f\"   {key}: {value}\")\n",
    "\n",
    "print(f\"\\nüí∞ Prediction: {result}\")\n",
    "print(f\"üéØ Confidence: {confidence:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "interactive_prediction"
   },
   "source": [
    "## üéÆ Interactive Prediction (Manual Input)\n",
    "\n",
    "Create your own employee profile and get predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "custom_prediction",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [],
   "source": [
    "# Interactive prediction function\n",
    "def predict_salary():\n",
    "    print(\"üéÆ Custom Employee Salary Prediction\")\n",
    "    print(\"=\" * 50)\n",
    "    print(\"Enter employee details (press Enter for default values):\")\n",
    "    \n",
    "    # Get user inputs\n",
    "    age = input(\"üë§ Age (default: 30): \") or \"30\"\n",
    "    hours = input(\"‚è∞ Hours per week (default: 40): \") or \"40\"\n",
    "    education_num = input(\"üéì Education years (default: 13): \") or \"13\"\n",
    "    \n",
    "    # Create prediction data\n",
    "    custom_data = {\n",
    "        'age': int(age),\n",
    "        'hours-per-week': int(hours),\n",
    "        'educational-num': int(education_num),\n",
    "        'capital-gain': 0,\n",
    "        'capital-loss': 0,\n",
    "        'fnlwgt': 100000\n",
    "    }\n",
    "    \n",
    "    # Add categorical features with default values\n",
    "    for col in categorical_columns:\n",
    "        if col in X.columns:\n",
    "            custom_data[col] = 0\n",
    "    \n",
    "    # Create DataFrame and predict\n",
    "    custom_df = pd.DataFrame([custom_data])\n",
    "    custom_df = custom_df.reindex(columns=X.columns, fill_value=0)\n",
    "    \n",
    "    prediction = model.predict(custom_df)[0]\n",
    "    probability = model.predict_proba(custom_df)[0]\n",
    "    \n",
    "    result = \"<=50K\" if prediction == 0 else \">50K\"\n",
    "    confidence = probability[prediction]\n",
    "    \n",
    "    print(f\"\\nüìä Results:\")\n",
    "    print(f\"üí∞ Predicted Income: {result}\")\n",
    "    print(f\"üéØ Confidence: {confidence:.2%}\")\n",
    "    print(f\"üìà Probability Distribution: <=50K: {probability[0]:.2%}, >50K: {probability[1]:.2%}\")\n",
    "\n",
    "# Run the prediction function\n",
    "predict_salary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "summary_cell"
   },
   "source": [
    "## üìù Project Summary\n",
    "\n",
    "### üéØ Achievements:\n",
    "- ‚úÖ Successfully loaded and preprocessed employee data\n",
    "- ‚úÖ Performed exploratory data analysis with visualizations\n",
    "- ‚úÖ Implemented feature encoding for categorical variables\n",
    "- ‚úÖ Trained a Logistic Regression model for salary prediction\n",
    "- ‚úÖ Evaluated model performance with multiple metrics\n",
    "- ‚úÖ Created interactive prediction functionality\n",
    "\n",
    "### üìä Key Results:\n",
    "- **Model Type**: Logistic Regression\n",
    "- **Accuracy**: Check the evaluation cell above for actual accuracy\n",
    "- **Features**: Demographic and work-related attributes\n",
    "- **Target**: Binary classification (<=50K vs >50K)\n",
    "\n",
    "### üöÄ Technologies Used:\n",
    "- **Python Libraries**: pandas, numpy, matplotlib, seaborn, scikit-learn\n",
    "- **Machine Learning**: Logistic Regression, Train-Test Split, Label Encoding\n",
    "- **Visualization**: Seaborn plots, Confusion Matrix\n",
    "- **Platform**: Google Colab for interactive development\n",
    "\n",
    "### üí° Next Steps:\n",
    "- Try different algorithms (Random Forest, XGBoost)\n",
    "- Implement feature selection techniques\n",
    "- Add hyperparameter tuning\n",
    "- Create a web deployment using Streamlit\n",
    "\n",
    "---\n",
     ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
